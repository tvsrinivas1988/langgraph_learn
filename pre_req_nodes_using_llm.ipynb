{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d09d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ebe8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7275e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,List\n",
    "class ChatState(TypedDict):\n",
    "    di_error_messages: List[BaseMessage]\n",
    "    dq_error_messages: List[BaseMessage]\n",
    "    dp_error_messages: List[BaseMessage]\n",
    "    afl_job_name: str\n",
    "    router_node_accessed: str\n",
    "    di_node_accessed: str\n",
    "    dp_nodes_accessed: str\n",
    "    dq_node_accessed: str\n",
    "    dummy_node_accessed: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e54dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using an LLM as simple ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a52c6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "model=\"openai/gpt-oss-20b\",\n",
    "temperature=0,\n",
    "max_tokens=None,\n",
    "reasoning_format=\"parsed\",\n",
    "timeout=None,\n",
    "max_retries=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b87007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='DI module', additional_kwargs={'reasoning_content': 'We need to interpret the instruction: \"You are a helpful L3 IT Ops assistant that bifurcates the DIJB0001 to one of these 3 : DI module , DP Module or DQ Module. If you dont know you say Dummy Module.\"\\n\\nSo we need to classify DIJB0001 into one of DI module, DP Module, DQ Module. If unknown, say Dummy Module.\\n\\nWe need to know what DIJB0001 refers to. It might be a code for a module. Without context, we guess. DIJB0001 could be a code for a DI module? The prefix DI might indicate DI module. But we need to be careful. The instruction says \"bifurcates the DIJB0001 to one of these 3: DI module, DP Module or DQ Module.\" So we need to decide which module it belongs to. The code DIJB0001: DI prefix suggests DI module. So answer: DI module.\\n\\nThus respond: DI module.'}, response_metadata={'token_usage': {'completion_tokens': 216, 'prompt_tokens': 124, 'total_tokens': 340, 'completion_time': 0.222747102, 'prompt_time': 0.006271919, 'queue_time': 0.199769829, 'total_time': 0.229019021}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_80501ff3a1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--98e84607-7cb8-4797-974f-cb23e592d61d-0', usage_metadata={'input_tokens': 124, 'output_tokens': 216, 'total_tokens': 340})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful L3 IT Ops assistant that bifurcates the  {input} to one of these 3 : DI module , DP Module or DQ Module. If you dont know you say Dummy Module.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \n",
    "        \"input\": \"DIJB0001\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180a127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b9cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2352cf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3364f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fb1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afe48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2dc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d292715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

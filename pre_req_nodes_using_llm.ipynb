{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d09d450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd6f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7275e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,List\n",
    "class ChatState(TypedDict):\n",
    "    di_error_messages: List[BaseMessage]\n",
    "    dq_error_messages: List[BaseMessage]\n",
    "    dp_error_messages: List[BaseMessage]\n",
    "    afl_job_name: str\n",
    "    router_node_accessed: str\n",
    "    di_node_accessed: str\n",
    "    dp_nodes_accessed: str\n",
    "    dq_node_accessed: str\n",
    "    dummy_node_accessed: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e54dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using an LLM as simple ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52c6838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "model=\"openai/gpt-oss-20b\",\n",
    "temperature=0,\n",
    "max_tokens=None,\n",
    "reasoning_format=\"parsed\",\n",
    "timeout=None,\n",
    "max_retries=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b87007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Dummy Module', additional_kwargs={'reasoning_content': 'We need to parse the instruction: \"You are a helpful L3 IT Ops assistant that bifurcates the DMJB0001 to one of these 3 : DI module , DP Module or DQ Module. If the module name starts with DI then its DI and likewise . If you dont know you say Dummy Module.\"\\n\\nWe have DMJB0001. The module name starts with \"DMJB\". That doesn\\'t start with DI, DP, or DQ. So we don\\'t know. According to instruction, if you don\\'t know, say Dummy Module. So answer: Dummy Module.'}, response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 137, 'total_tokens': 267, 'completion_time': 0.136563619, 'prompt_time': 0.007018905, 'queue_time': 0.20016126, 'total_time': 0.143582524}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e99e93f2ac', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--90dca8c6-53a3-46ff-a33a-2d99a6259378-0', usage_metadata={'input_tokens': 137, 'output_tokens': 130, 'total_tokens': 267})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful L3 IT Ops assistant that bifurcates the  {input} to one of these 3 : DI module , DP Module or DQ Module. If the module name starts with DI then its DI and likewise . If you dont know you say Dummy Module.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \n",
    "        \"input\": \"DMJB0001\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b180a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # read from .env file\n",
    "\n",
    "USER = os.getenv(\"DB_USER\")\n",
    "PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "HOST = os.getenv(\"DB_HOST\")\n",
    "PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41b9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def get_latest_error(job_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Connects to PostgreSQL, queries error_logs for the latest error for a given job, \n",
    "    and returns the result.\n",
    "    Args:\n",
    "    job_name : Airflow job name that as failed\n",
    "    \"\"\"\n",
    "\n",
    "    # Connection details (could also be read from environment or secrets.toml)\n",
    "    DB_USER = os.getenv(\"DB_USER\", \"your_user\")\n",
    "    DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"your_password\")\n",
    "    DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "    DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "    DB_NAME = os.getenv(\"DB_NAME\", \"your_db\")\n",
    "\n",
    "    conn_str = (\n",
    "        f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "        \"?sslmode=require\"\n",
    "    )\n",
    "\n",
    "    engine = create_engine(conn_str)\n",
    "\n",
    "    query = text(\"\"\"\n",
    "        SELECT *\n",
    "        FROM error_logs\n",
    "        WHERE job_name = :job_name\n",
    "        ORDER BY created_at \n",
    "        LIMIT 1;\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(query, {\"job_name\": job_name}).fetchone()\n",
    "            if result:\n",
    "                return dict(result._mapping)  # Convert Row to dict\n",
    "            else:\n",
    "                return {\"message\": f\"No errors found for job: {job_name}\"}\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        return {\"error\": f\"SQLAlchemy error: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {str(e)}\"}\n",
    "    finally:\n",
    "        engine.dispose()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2352cf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'module_name': 'DI', 'job_name': 'customer_ingestion', 'error_code': 'SRC001', 'error_message': 'Source file missing for 2025-09-30', 'stack_trace': None, 'severity': 'ERROR', 'created_at': datetime.datetime(2025, 10, 3, 19, 38, 36, 804027), 'created_by': 'ETL_Pipeline'}\n"
     ]
    }
   ],
   "source": [
    "job_name_input = \"customer_ingestion\"\n",
    "latest_error = get_latest_error(job_name_input)\n",
    "print(latest_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d3364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful L3 IT Ops assistant that bifurcates the  {input} to one of these 3 : DI module , DP Module or DQ Module. If the module name starts with DI then its DI and likewise . If you dont know you say Dummy Module. If you are asked to find the latest error for the job use the tool call available.\" \n",
    "            ,\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "llm_with_tools  = llm.bind_tools([get_latest_error])\n",
    "chain = prompt | llm_with_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132fb1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='DIJB0001 belongs to the **DI Module**.', additional_kwargs={'reasoning_content': 'We need to classify DIJB0001 into DI module, DP Module, or DQ Module based on module name starts with DI, DP, DQ. DIJB0001 starts with DI, so DI module. Also if asked to find latest error for the job, we can call tool. But user just gave DIJB0001. So respond: DI module.'}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 237, 'total_tokens': 334, 'completion_time': 0.101058245, 'prompt_time': 0.012386148, 'queue_time': 0.245050525, 'total_time': 0.113444393}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_80501ff3a1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ada12e5c-e22d-432f-8920-611caae35a8e-0', usage_metadata={'input_tokens': 237, 'output_tokens': 97, 'total_tokens': 334})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \n",
    "        \"input\": \"DIJB0001\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3afe48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call=chain.invoke(\n",
    "    {\n",
    "        \n",
    "        \"input\": \"What is the latest error for the job customer_ingestion\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06c2dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_latest_error',\n",
       "  'args': {'job_name': 'customer_ingestion'},\n",
       "  'id': 'fc_f5c00cfb-7266-4851-9e08-e6925e97a27b',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d292715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
